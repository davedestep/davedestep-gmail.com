---
title: "Standup NLP"
author: "David DeStephano"
date: "March 28, 2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(tidytext)
library(stringr)
library(SnowballC)
```


Inspired by these projects, one comparing gender deifferences between commencement speeches, and the other compariring standup specials 

https://towardsdatascience.com/using-nlp-to-explore-leadership-inspiration-f2e0b805d01c

https://medium.com/nwamaka-imasogie/stand-up-comedy-and-nlp-c7d64002520c

Lets pick 5 mens and 5 womens specials from the last 10 years from the most popular stand up specials on [IMDB](https://www.imdb.com/search/title/?title_type=tv_special&genres=comedy&explore=title_type,genres) with no repeating comedians. Was not sure if I should include Hannah Gadsby: [Nanette](https://scrapsfromtheloft.com/2018/07/21/hannah-gadsby-nanette-transcript/) or not because it is too serious


Men:
```{r echo=FALSE}
 #Not worth doing this just use txt files
# # get HTML object
# library(stringi)
# thepage = readLines("https://scrapsfromtheloft.com/2020/03/21/bert-kreischer-hey-big-boy-transcript/")
# p<-thepage[312:354]
# dp <- Corpus(VectorSource(p))
# inspect(dp)
# docs <- tm_map(dp, function(x) stri_replace_all_regex(x, "<.+?>", " "))
# docs <- tm_map(docs, function(x) stri_replace_all_fixed(x, "\t", " "))
# docs <- tm_map(docs, PlainTextDocument)
# docs <- tm_map(docs, stripWhitespace)
# docs <- tm_map(docs, removeWords, stopwords("english"))
# docs <- tm_map(docs, removePunctuation)
# docs <- tm_map(docs, tolower)
# docs[[1]]
# 
# 
# library(rvest)
# html_data <- read_html("https://scrapsfromtheloft.com/2020/03/21/bert-kreischer-hey-big-boy-transcript/")%>% html_nodes("div")

```

https://scrapsfromtheloft.com/2020/03/21/bert-kreischer-hey-big-boy-transcript/

https://scrapsfromtheloft.com/2020/03/12/marc-maron-end-times-fun-transcript/

https://scrapsfromtheloft.com/2020/03/01/pete-davidson-alive-from-new-york-transcript/

https://scrapsfromtheloft.com/2019/08/26/dave-chappelle-sticks-stones-transcript/

https://scrapsfromtheloft.com/2018/03/15/ricky-gervais-humanity-transcript/

https://scrapsfromtheloft.com/2020/03/25/tom-segura-ball-hog-transcript/


Women:
https://scrapsfromtheloft.com/2018/09/13/iliza-shlesinger-war-paint-transcript/

https://scrapsfromtheloft.com/2018/07/21/hannah-gadsby-nanette-transcript/

https://scrapsfromtheloft.com/2018/05/15/ali-wong-hard-knock-wife-full-transcript/

https://scrapsfromtheloft.com/2017/06/20/amy-schumer-leather-special-2017-full-transcript/

https://scrapsfromtheloft.com/2019/10/04/nikki-glaser-bangin-transcript/

What's her name's netflix transcript pulled from web tools

```{r  message=FALSE, warning=FALSE}
standup <- data_frame(file = paste0("C:\\Users\\daved\\Documents\\Advanced analytic techniques\\Lab 2\\standup_NLP\\up\\",
                                        c("taylor_tomlinson.txt","ali.txt","amy.txt", "burt.txt", "dave.txt", "hannah.txt", "iliza.txt", "marc_maron.txt", "nikki.txt", "pete.txt", "ricky.txt", "tom.txt"))) %>%
  mutate(text = map(file, read_lines)) %>%
  unnest() %>%
  group_by(file = str_sub(basename(file), 1, -5)) %>%
  mutate(line_number = row_number()) %>%
  ungroup() %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) 
#%>%mutate(word = wordStem(word)) 


head(standup) %>% knitr::kable()

```



```{r message=FALSE, warning=FALSE}
##seperate into men and women?
standup2 <- standup %>% 
  mutate(gender=ifelse(file=="burt"|file=="dave"|file=="marc_maron"|file=="pete"|file=="ricky"|file=="tom", "male", "female"))

## count each word per speech 

pw <- standup2[,c("gender","word")]
d<-  count_(pw, c("gender", "word"))

## make a document term matrix ##

pwdtm <- d %>%
  cast_dtm(gender, word, n)

## make the dtm into a dataframe ##

mpwdtm<-as.matrix(pwdtm)
df.mpwdtm<-as.data.frame(mpwdtm)

## make the dtm into a tdm instead ##

t.t <- t(mpwdtm)
head(t.t, 50)


df.t.t <- as.data.frame(t.t)

summing <- function(x) x/sum(x, na.rm=T)

df.t.t.2 <- apply(df.t.t, 2, summing)

df.t.t$names<-rownames(df.t.t)
df.t.t <- as.data.frame(t.t)
df.t.t$names<-rownames(df.t.t)
head(df.t.t)

df.t.t.2 <- as.data.frame(df.t.t.2)
df.t.t.2$names<-rownames(df.t.t.2)
df.t.t.2 <- as.data.frame(df.t.t.2)

total <- merge(df.t.t,df.t.t.2,by="names")

head(total)
```


#What are the most female words vs male?
```{r message=FALSE, warning=FALSE}
total$male.over.female = (total$male.y) - (total$female.y)
sort.OT <- total[order(total$male.over.female) , ]
sort.OT[1:30, ]
```

#What about male vs femal?
```{r message=FALSE, warning=FALSE}
total$female.over.male = (total$female.y) - (total$male.y)
sort.OT <- total[order(total$female.over.male) , ]
sort.OT[1:30, ]
```

There are several differences that boil down to a particular comic (such as lesbian for Hannah Gadsby), but in general men tend to use more curse words and "ums" or "uhs", while women use gendered nouns like "guys", "girls", "women"; relationship or sex related nouns and verbs like "love", sex", "blow", "baby" and in general use far fewer curses besides "god".

Because there are so many comics and specials being compared to eachother, I think this does specify some differences in the words and things males vs females talk about in standup, but I do not think it proves that the bag of words are different inherently. Would need to do some other kind of analysis I think to get at how they are different rather than if they can be proven to be different using a bag of words approach.


#Another way to different word choices
```{r message=FALSE, warning=FALSE}
total %>% ggplot(aes(x=male.y, y=female.y)) + geom_text(aes(label=names), size = 4.5) 
```


#How similar are the male and female texts? Using statistical tests of association

##Linear regression:
##High correlation because different comics? Large sample so a lot of words?
```{r message=FALSE, warning=FALSE}
sum(total$male.x, na.rm=T)
sum(total$female.x, na.rm=T)


cor(t.t, method="spearman")


m1a = lm(female ~ male, df.t.t)
m1b = lm(female ~ male + I(male^2), df.t.t)
m2a = lm(female.y ~ male.y , total)
m2b = lm(female.y ~ male.y + I(male.y^2), total)

library(stargazer)
stargazer(m1a, m1b, type = "text", single.row = TRUE)

```

Male and female specials have a low pearson correlation coefficient/are slightly negatively correlated, but are highly associated in the regression analysis


##Cosine 
```{r message=FALSE, warning=FALSE}
library(lsa)
cosine(t.t)

```

Male and female specials have a cosine similarity of 0.90.


##Chi-squared test approach
```{r message=FALSE, warning=FALSE}
ctable <- table(t.t)
chisq.test(ctable)
```
Chi-squared test was significant.

I think these findings show that the texts are not inherently different, and are quite similar in many ways, but different words are being used more frequently between the male and female comics (as shown by the chi-squared test) and relative frequencies

#Word cloud individual words
```{r  message=FALSE, warning=FALSE}
library(wordcloud)
library(RColorBrewer)

wordcloud(total$names, total$male.x, min.freq=2, random.color=T, ordered.colors=T)
wordcloud(total$names, total$female.x, min.freq=2, random.color=T, ordered.colors=T)
```

#I want to try clustering to see if comedians are seperated by gender or style.
```{r message=FALSE, warning=FALSE}
cname <- file.path("C:\\Users\\daved\\Documents\\Advanced analytic techniques\\Lab 2\\standup_NLP", "up")   
cname   
dir(cname)   

library(tm)   
docs <- Corpus(DirSource(cname))   

summary(docs)   

#inspect(docs[2])

dtm <- DocumentTermMatrix(docs)

dtmss <- removeSparseTerms(dtm, 0.15) # This makes a matrix that is only 15% empty space, maximum.   
inspect(dtmss) 

library(cluster)   
d <- dist(dtmss, method="euclidian")   
fit <- hclust(d=d, method="ward")   
fit   

plot(fit, hang=-1)  

plot.new()
plot(fit, hang=-1)
groups <- cutree(fit, k=3)   # "k=" defines the number of clusters you are using   
rect.hclust(fit, k=3, border="red") # draw dendogram with red borders around the 5 clusters
```

I find it very interesting that Ricky Gervais, Dave Chapelle, and Hannah Gadsby and Ali Wong (who I am less familiar with). Perhaps this is because they give the most social commentary during their sets? While Burt, Pete, Amy Schumer, and Taylor Tomlinson may use the most vulgarity?


#Lets look at bi grams too
##But for each comedian this time
```{r message=FALSE, warning=FALSE}
standup_bi <- data_frame(file = paste0("C:\\Users\\daved\\Documents\\Advanced analytic techniques\\Lab 2\\standup_NLP\\up\\",
                                        c("taylor_tomlinson.txt","ali.txt","amy.txt", "burt.txt", "dave.txt", "hannah.txt", "iliza.txt", "marc_maron.txt", "nikki.txt", "pete.txt", "ricky.txt", "tom.txt"))) %>%
  mutate(text = map(file, read_lines)) %>%
  unnest() %>%
  group_by(file = str_sub(basename(file), 1, -5)) %>%
  mutate(line_number = row_number()) %>%
  ungroup() %>%
  #unnest_tokens(word, text) %>%
  unnest_tokens(word, text, token = "ngrams", n = 2) %>%  ## how to get bigrams instead 
  anti_join(stop_words) 
#%>%mutate(word = wordStem(word)) 

standup_bi %>%
 count(word, sort = TRUE)

bigrams_separated <- standup_bi %>%
 separate(word, c("word1", "word2"), sep = " ")


bigrams_filtered <- bigrams_separated %>%
 filter(!word1 %in% stop_words$word) %>%
 filter(!word2 %in% stop_words$word) 

bigram_counts <- bigrams_filtered %>%
 count(word1, word2, sort = TRUE)

bigram_counts

bigrams_united <- bigrams_filtered %>%
 unite(word, word1, word2, sep = " ")

bigrams_united


pw = bigrams_united[,c("file","word")]
d= count_(pw, c("file", "word"))
pwdtm = d %>%
 cast_dtm(file, word, n)
## make the dtm into a dataframe ##
mpwdtm=as.matrix(pwdtm)
df.mpwdtm=as.data.frame(mpwdtm)
## make the dtm into a tdm instead ##
t.t = t(mpwdtm)
#head(t.t, 50)
df.t.t = as.data.frame(t.t)


summing = function(x) x/sum(x, na.rm=T)
df.t.t.2 = apply(df.t.t, 2, summing)
df.t.t$names<-rownames(df.t.t)
df.t.t = as.data.frame(t.t)
df.t.t$names<-rownames(df.t.t)
#head(df.t.t)
df.t.t.2 = as.data.frame(df.t.t.2)
df.t.t.2$names<-rownames(df.t.t.2)
df.t.t.2 = as.data.frame(df.t.t.2)
total <- merge(df.t.t,df.t.t.2,by="names")
head(total)

pivoted<-total %>% select(names, ends_with(".x")) %>% 
  pivot_longer(-names, names_to = "Comic", values_to = "n") %>%  
  filter(!grepl('audience', names))%>%  
  filter(!grepl('crowd', names))%>%  
  filter(!grepl('gonna', names))%>%  
  filter(!grepl('NA', names))%>% 
  filter(n>4) %>% 
   arrange(desc(n))


pivoted %>% head(40) %>% knitr::kable()


```

Pretty funny, my favorite was ricky's


#Rerun original analysis with bigrams
```{r message=FALSE, warning=FALSE}

standup_bi <- data_frame(file = paste0("C:\\Users\\daved\\Documents\\Advanced analytic techniques\\Lab 2\\standup_NLP\\up\\",
                                        c("taylor_tomlinson.txt","ali.txt","amy.txt", "burt.txt", "dave.txt", "hannah.txt", "iliza.txt", "marc_maron.txt", "nikki.txt", "pete.txt", "ricky.txt", "tom.txt"))) %>%
  mutate(text = map(file, read_lines)) %>%
  unnest() %>%
  group_by(file = str_sub(basename(file), 1, -5)) %>%
  mutate(line_number = row_number()) %>%
  ungroup() %>%
  #unnest_tokens(word, text) %>%
  unnest_tokens(word, text, token = "ngrams", n = 2) %>%  ## how to get bigrams instead 
  anti_join(stop_words)
#%>%mutate(word = wordStem(word)) 

standup_bi <- standup_bi %>% 
  mutate(gender=ifelse(file=="burt"|file=="dave"|file=="marc_maron"|file=="pete"|file=="ricky"|file=="tom", "male", "female")) %>% 
  select(-file)

standup_bi %>%
 count(word, sort = TRUE)

bigrams_separated <- standup_bi %>%
 separate(word, c("word1", "word2"), sep = " ")


bigrams_filtered <- bigrams_separated %>%
 filter(!word1 %in% stop_words$word) %>%
 filter(!word2 %in% stop_words$word) 

bigram_counts <- bigrams_filtered %>%
 count(word1, word2, sort = TRUE)

bigram_counts

bigrams_united <- bigrams_filtered %>%
 unite(word, word1, word2, sep = " ")

bigrams_united


pw = bigrams_united[,c("gender","word")]
d= count_(pw, c("gender", "word"))
pwdtm = d %>%
 cast_dtm(gender, word, n)
## make the dtm into a dataframe ##
mpwdtm=as.matrix(pwdtm)
df.mpwdtm=as.data.frame(mpwdtm)
## make the dtm into a tdm instead ##
t.t = t(mpwdtm)
#head(t.t, 50)
df.t.t = as.data.frame(t.t)


summing = function(x) x/sum(x, na.rm=T)
df.t.t.2 = apply(df.t.t, 2, summing)
df.t.t$names<-rownames(df.t.t)
df.t.t = as.data.frame(t.t)
df.t.t$names<-rownames(df.t.t)
#head(df.t.t)
df.t.t.2 = as.data.frame(df.t.t.2)
df.t.t.2$names<-rownames(df.t.t.2)
df.t.t.2 = as.data.frame(df.t.t.2)
total <- merge(df.t.t,df.t.t.2,by="names")


total<-total %>% 
  filter(!grepl('audience', names))%>%  
  filter(!grepl('crowd', names))%>%  
  filter(!grepl('gonna', names))%>%  
  filter(!grepl('NA', names))%>% 
   arrange(desc(female.x, male.x))

head(total)
```

#What are the most female bigrams vs male?
```{r message=FALSE, warning=FALSE}
total$male.over.female = (total$male.y) - (total$female.y)
sort.OT <- total[order(total$male.over.female) , ]
sort.OT[1:30, ]
```

#What about male vs female?
```{r message=FALSE, warning=FALSE}
total$female.over.male = (total$female.y) - (total$male.y)
sort.OT <- total[order(total$female.over.male) , ]
sort.OT[1:30, ]
```

```{r}
total %>% ggplot(aes(x=male.y, y=female.y)) + geom_text(aes(label=names), size = 3.5) 
```

So I think this makes a lot more sense then looking at individual words. There is definitely a lot more differences in bigrams between men and women. Although this example definitely seems to drap on individual bigrams said by certain comics, there are some funny examples of gender differences.

#Word cloud bigrams
```{r  message=FALSE, warning=FALSE}
library(wordcloud)
library(RColorBrewer)

wordcloud(total$names, total$male.x, min.freq=6, random.color=T, ordered.colors=T)
wordcloud(total$names, total$female.x, min.freq=6, random.color=T, ordered.colors=T)
```

